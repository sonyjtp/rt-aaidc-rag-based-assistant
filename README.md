# ğŸ¤– RAG-Based AI Assistant

> A production-ready Retrieval-Augmented Generation (RAG) chatbot that answers questions exclusively from a set of custom documents using LangChain, ChromaDB, and multiple LLM providers.

[![Python Version](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-CC%20BY--NC--SA%204.0-blue.svg)](LICENSE)
[![Tests](https://img.shields.io/badge/tests-passing-brightgreen.svg)]()
[![Code Coverage](https://img.shields.io/badge/coverage-94.41%25-brightgreen.svg)]()
[![Pylint](https://github.com/sonyjtp/rag-based-assistant/actions/workflows/pylint.yml/badge.svg)](https://github.com/sonyjtp/rag-based-assistant/actions/workflows/pylint.yml)

[Quick Start](#-quick-start) â€¢ [Features](#-features) â€¢ [Installation](#-installation)


---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [Quick Start](#-quick-start)
- [Installation](#-installation)
- [Configuration](#-configuration)
- [Usage](#-usage)
- [Project Architecture](#-project-architecture)
- [Project Structure](#-project-structure)
- [Customization Guide](#-customization-guide)
- [Troubleshooting](#-troubleshooting)
- [Documentation](#-documentation)
- [License](#-license)


---

## ğŸ¯ Overview

This project implements a **Retrieval-Augmented Generation (RAG)** chatbot that:

- ğŸ“š **Loads custom documents** from your `data/` directory
- ğŸ” **Chunking**: Split documents into chunks and add metadata.
- ğŸ’¾ **Storage**: Store each chunk's embedding (vector), the chunk text, and metadata in ChromaDB for retrieval.
- ğŸ¤ **Answers questions** exclusively from your documents
- ğŸ§  **Maintains conversation** memory across multiple interactions
- ğŸ”Œ **Supports multiple LLMs**: OpenAI, Groq, Google Gemini
- ğŸ›¡ï¸ **Prevents hallucination** with strict prompt constraints
- ğŸ“Š **Tracks reasoning** with configurable strategies

**Key Constraint**: The assistant **only answers questions based on the provided documents**. Questions that cannot be answered from the documents are rejected with: *"I'm sorry, that information is not known to me."*

---

## âœ¨ Features

### Core RAG Capabilities
- âœ… Document loading from text files
- âœ… Intelligent text chunking with overlap
- âœ… Semantic search using ChromaDB's embedding-based similarity search
- âœ… Context-aware question answering
- âœ… Document metadata preservation (title, tags, filename)

### Memory Management
- âœ… **Buffer Memory** (simple_buffer): Stores full conversation history.
- âœ… **Sliding Window Memory** (summarization_sliding_window) â€” default: keeps recent messages plus a running summarized history to stay within token limits.
- âœ… **Summarization** (summary): Maintains a running summary of the conversation.
- âœ… **None** (none): Disables conversation memory.

### LLM Integration
- âœ… **OpenAI GPT-4** / GPT-4o-mini
- âœ… **Groq Llama 3.1** (fast inference)
- âœ… **Google Gemini** Pro
- âœ… Automatic fallback to next available provider

### Reasoning Strategies

- âœ… **RAG-Enhanced Reasoning** (rag_enhanced_reasoning) â€” default: Retrieve relevant documents first, then apply reasoning grounded in those documents; `enabled: true`.
- âœ… **Chain-of-Thought** (chain_of_thought): Step-by-step internal reasoning before the final answer; `enabled: true`.
- âœ… **ReAct** (react): Interleave reasoning and actions (e.g., document retrieval) dynamically; `enabled: false`.
- âœ… **Few-Shot Prompting** (few_shot_prompting): Include examples in the prompt to guide format and style; `enabled: true`.
- âœ… **Metacognitive Prompting** (metacognitive_prompting): Reflect on confidence, limitations, and uncertainty; `enabled: true`.

### Safety & Quality
- âœ… **Hallucination Prevention**: Strict prompt constraints
- âœ… **Input Validation**: Document and query validation
- âœ… **Error Handling**: Comprehensive exception handling
- âœ… **Logging**: Detailed logging throughout
- âœ… **Test Cases**: Code coverage maintained above 85%

### User Interfaces
- âœ… **CLI Interface** (`app.py`): Command-line chatbot
- âœ… **Streamlit UI** (`streamlit_app.py`): Web-based interface
- âœ… **API Ready**: Can be integrated with FastAPI/Flask

---

## ğŸš€ Quick Start

### Prerequisites
- **Python 3.8+** (Tested with 3.12.12 âœ…)
- **API Key** for at least one LLM provider:
  - OpenAI: `OPENAI_API_KEY`
  - Groq: `GROQ_API_KEY`
  - Google: `GOOGLE_API_KEY`

### 1ï¸âƒ£ Clone & Setup (2 minutes)

```bash
# Clone the repository
git clone https://github.com/sonyjtp/rag-based-assistant.git
cd rag-based-assistant

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2ï¸âƒ£ Configure API Key (1 minute)

```bash
# Copy example env file
cp .env_example .env

# Edit .env with your API key
# Choose ONE provider:
# Option 1: OpenAI
OPENAI_API_KEY=your_openai_key_here

# Option 2: Groq (recommended - fast and free)
GROQ_API_KEY=your_groq_key_here

# Option 3: Google Gemini
GOOGLE_API_KEY=your_google_key_here
```

### 3ï¸âƒ£ Add Your Documents (2 minutes)

```bash
# Replace sample files in data/ with your documents
# Files should be .txt format

ls data/
# Output: your_document.txt, another_doc.txt, ...
```

### 4ï¸âƒ£ Run the Assistant (30 seconds)

**CLI Version:**
```bash
python src/app.py
```

**Web UI (Streamlit):**
```bash
streamlit run src/streamlit_app.py
```

> ğŸ“– For a detailed walkthrough of the web interface, see [UI_GUIDE.md](UI_GUIDE.md).

---

## ğŸ“¦ Installation

### Full Installation with Development Tools

```bash
# Clone repository
git clone https://github.com/yourusername/rt-aaidc-rag-based-assistant.git
cd rt-aaidc-rag-based-assistant

# Create virtual environment
python -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Install development/test dependencies (optional)
pip install -r requirements-dev.txt

# Set up pre-commit hooks for automatic code formatting
pre-commit install
```

---

## âš™ï¸ Configuration

See [Quick Start](#-quick-start) for environment variable setup (`OPENAI_API_KEY`, `GROQ_API_KEY`, `GOOGLE_API_KEY`).

For advanced configuration options, see:
- `src/config.py` â€” Core settings (chunk size, embedding model, LLM selection)
- `config/memory_strategies.yaml` â€” Memory strategy definitions
- `config/reasoning_strategies.yaml` â€” Reasoning approach configurations
- `config/prompt-config.yaml` â€” System prompts and safety constraints

### ChromaDB Quota Limitation

**Important**: ChromaDB's free tier has a quota limit of **300 records maximum**. When you exceed this limit, you'll encounter an error.

The current batch size is set to 300 records ( `INSERT_BATCH_SIZE = 300` in `src/config.py` ). This limitation affects latency of initial ingestion.


---

## ğŸ’¬ Usage

### CLI Usage

```bash
python src/app.py

# Prompts you to ask questions
# Type 'quit' to exit

> What is the main topic of the documents?
Assistant: Based on the documents, the main topics are...

> Tell me more
Assistant: [Provides additional context from memory]

> quit
Goodbye!
```

### Streamlit Web Interface

```bash
streamlit run src/streamlit_app.py

# Opens http://localhost:8501
# - Sidebar: Clear history, configure settings
# - Main: Chat interface
# - Auto-saves conversation
```


---

## ğŸ—ï¸ Project Architecture

### System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      USER INTERFACE LAYER                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   CLI Interface      â”‚              â”‚  Streamlit Web UI    â”‚     â”‚
â”‚  â”‚   (app.py)           â”‚              â”‚  (streamlit_app.py)  â”‚     â”‚
â”‚  â”‚   â€¢ Local shell      â”‚              â”‚  â€¢ Browser-based     â”‚     â”‚
â”‚  â”‚   â€¢ Direct queries   â”‚              â”‚  â€¢ Chat history      â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚                                  â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚   REQUEST PROCESSING LAYER  â”‚
                  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                  â”‚ â”‚  Persona Handler       â”‚  â”‚
                  â”‚ â”‚  â€¢ Meta-question       â”‚  â”‚
                  â”‚ â”‚    detection           â”‚  â”‚
                  â”‚ â”‚  â€¢ README extraction   â”‚  â”‚
                  â”‚ â”‚  â€¢ Answer validation   â”‚  â”‚
                  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚  RAG Assistant CORE         â”‚
                  â”‚  â€¢ invoke(query)            â”‚
                  â”‚  â€¢ add_documents()          â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                   â”‚                  â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚Search       â”‚    â”‚Query      â”‚    â”‚Hallucination â”‚
    â”‚Manager      â”‚    â”‚Processor  â”‚    â”‚Prevention    â”‚
    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚â€¢Add docs    â”‚    â”‚â€¢Context   â”‚    â”‚â€¢Similarity   â”‚
    â”‚â€¢Search      â”‚    â”‚ augment   â”‚    â”‚ threshold    â”‚
    â”‚â€¢VectorDB    â”‚    â”‚â€¢Memory    â”‚    â”‚â€¢Context      â”‚
    â”‚ delegation  â”‚    â”‚ retrieval â”‚    â”‚ validation   â”‚
    â”‚â€¢Flatten     â”‚    â”‚â€¢Query     â”‚    â”‚â€¢LLM-based    â”‚
    â”‚ results     â”‚    â”‚ refinementâ”‚    â”‚ relevance    â”‚
    â”‚â€¢LLM context â”‚    â”‚           â”‚    â”‚ check        â”‚
    â”‚ validation  â”‚    â”‚           â”‚    â”‚â€¢Error        â”‚
    â”‚             â”‚    â”‚           â”‚    â”‚ responses    â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
         â”‚                   â”‚                  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   LANGUAGE & REASONING LAYER         â”‚
        â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚ â”‚  Prompt Builder                 â”‚  â”‚
        â”‚ â”‚  â€¢ System prompts               â”‚  â”‚
        â”‚ â”‚  â€¢ Constraints enforcement      â”‚  â”‚
        â”‚ â”‚  â€¢ Response formatting          â”‚  â”‚
        â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚ â”‚  Reasoning Strategy Loader      â”‚  â”‚
        â”‚ â”‚  â€¢ Chain-of-Thought             â”‚  â”‚
        â”‚ â”‚  â€¢ ReAct                        â”‚  â”‚
        â”‚ â”‚  â€¢ Few-Shot Prompting           â”‚  â”‚
        â”‚ â”‚  â€¢ Metacognitive Reasoning      â”‚  â”‚
        â”‚ â”‚  â€¢ RAG-Enhanced (default)       â”‚  â”‚
        â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚ â”‚  LLM Integration                â”‚  â”‚
        â”‚ â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
        â”‚ â”‚  Provider Selection:            â”‚  â”‚
        â”‚ â”‚  â€¢ OpenAI (GPT-4/4o-mini)       â”‚  â”‚
        â”‚ â”‚  â€¢ Groq (Llama 3.1)             â”‚  â”‚
        â”‚ â”‚  â€¢ Google Gemini Pro            â”‚  â”‚
        â”‚ â”‚  â€¢ Auto-fallback logic          â”‚  â”‚
        â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
        â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   KNOWLEDGE BASE LAYER               â”‚
        â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚ â”‚  Search Manager                 â”‚  â”‚
        â”‚ â”‚  â€¢ Add documents to VectorDB    â”‚  â”‚
        â”‚ â”‚  â€¢ Search for relevant docs     â”‚  â”‚
        â”‚ â”‚  â€¢ Flatten nested results       â”‚  â”‚
        â”‚ â”‚  â€¢ Log retrieval scores         â”‚  â”‚
        â”‚ â”‚  â€¢ LLM-based context            â”‚  â”‚
        â”‚ â”‚    relevance validation         â”‚  â”‚
        â”‚ â”‚  â€¢ VectorDB orchestration       â”‚  â”‚
        â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚ â”‚  VectorDB (ChromaDB)            â”‚  â”‚
        â”‚ â”‚  â€¢ Document chunks storage      â”‚  â”‚
        â”‚ â”‚  â€¢ Semantic search              â”‚  â”‚
        â”‚ â”‚  â€¢ Metadata indexing            â”‚  â”‚
        â”‚ â”‚  â€¢ Limit: 300 records (free)    â”‚  â”‚
        â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚ â”‚  Embeddings & Storage           â”‚  â”‚
        â”‚ â”‚  â€¢ Document chunks converted to â”‚  â”‚
        â”‚ â”‚    embeddings for storage       â”‚  â”‚
        â”‚ â”‚  â€¢ HuggingFace Transformers     â”‚  â”‚
        â”‚ â”‚  â€¢ all-mpnet-base-v2 (default)  â”‚  â”‚
        â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   STATE MANAGEMENT LAYER             â”‚
        â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚ â”‚  Memory Manager                 â”‚  â”‚
        â”‚ â”‚  â€¢ Strategy Pattern:            â”‚  â”‚
        â”‚ â”‚    - SlidingWindow (default)    â”‚  â”‚
        â”‚ â”‚    - SimpleBuffer               â”‚  â”‚
        â”‚ â”‚    - Summarization              â”‚  â”‚
        â”‚ â”‚    - None                       â”‚  â”‚
        â”‚ â”‚  â€¢ Token limit management       â”‚  â”‚
        â”‚ â”‚  â€¢ Conversation history         â”‚  â”‚
        â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

**System Architecture Overview:**

The system is organized into 7 interconnected layers that work together to process user queries and generate accurate answers:

1. **User Interface Layer**: Handles interaction through CLI and Streamlit web interface, accepting user queries and displaying responses.

2. **Request Processing Layer**: The Persona Handler detects meta-questions (questions about the system itself) and routes them to README extraction if needed.

3. **RAG Assistant Core**: The main orchestrator that coordinates between search, query processing, and hallucination prevention components.

4. **Core Processing Components**: Search Manager retrieves relevant documents from the vector database, Query Processor augments queries with conversation history, and Hallucination Prevention validates that retrieved documents are relevant using similarity thresholds.

5. **Language & Reasoning Layer**: Combines prompt building with multiple reasoning strategies (Chain-of-Thought, ReAct, Few-Shot, etc.) and integrates with LLM providers (OpenAI, Groq, Google Gemini).

6. **Knowledge Base Layer**: Manages document storage and semantic search through ChromaDB using embeddings for similarity matching.

7. **State Management Layer**: Maintains conversation history using configurable memory strategies (Sliding Window, Buffer, Summarization) to preserve context across interactions.

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CROSS-CUTTING CONCERNS & UTILITIES                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚File Utils   â”‚  â”‚Logger        â”‚  â”‚Config       â”‚  â”‚Error       â”‚ â”‚
â”‚  â”‚â€¢ Load docs  â”‚  â”‚â€¢ Structured  â”‚  â”‚â€¢ Centralizedâ”‚  â”‚Messages    â”‚ â”‚
â”‚  â”‚â€¢ Parse text â”‚  â”‚  logging     â”‚  â”‚  settings   â”‚  â”‚â€¢ User-     â”‚ â”‚
â”‚  â”‚â€¢ Chunking   â”‚  â”‚â€¢ File write  â”‚  â”‚â€¢ YAML cfg   â”‚  â”‚  friendly  â”‚ â”‚
â”‚  â”‚â€¢ Metadata   â”‚  â”‚â€¢ Debug mode  â”‚  â”‚â€¢ Env vars   â”‚  â”‚  responses â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚UI Utils     â”‚  â”‚String Utils  â”‚  â”‚README Extractor             â”‚ â”‚
â”‚  â”‚â€¢ Styling    â”‚  â”‚â€¢ Validation  â”‚  â”‚â€¢ Dynamic content extraction â”‚ â”‚
â”‚  â”‚â€¢ Colors     â”‚  â”‚â€¢ Formatting  â”‚  â”‚â€¢ Multi-section support      â”‚ â”‚
â”‚  â”‚â€¢ Layouts    â”‚  â”‚â€¢ Sanitizing  â”‚  â”‚â€¢ Fallback handling          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DATA FLOW: QUESTION â†’ ANSWER                                       â”‚
â”‚                                                                      â”‚
â”‚  1. User Query                                                       â”‚
â”‚       â†“                                                              â”‚
â”‚  2. Persona Handler (Meta-question check?)                           â”‚
â”‚       â”œâ”€ YES â†’ Extract from README & return                          â”‚
â”‚       â””â”€ NO â†’ Continue                                               â”‚
â”‚       â†“                                                              â”‚
â”‚  3. Query Processor (Augment with chat history)                      â”‚
â”‚       â†“                                                              â”‚
â”‚  4. Search Manager (Retrieve relevant documents)                     â”‚
â”‚       â”œâ”€ Convert to embedding                                        â”‚
â”‚       â”œâ”€ Search VectorDB                                             â”‚
â”‚       â””â”€ Rank & flatten results                                      â”‚
â”‚       â†“                                                              â”‚
â”‚  5. Hallucination Prevention (Validate similarity)                   â”‚
â”‚       â”œâ”€ Similarity â‰¥ threshold? â†’ Continue                          â”‚
â”‚       â””â”€ NO match? â†’ Return "not known to me"                        â”‚
â”‚       â†“                                                              â”‚
â”‚  6. Reasoning Strategy (Decide how to reason)                        â”‚
â”‚       â†“                                                              â”‚
â”‚  7. Prompt Builder (Create system + user prompt)                     â”‚
â”‚       â†“                                                              â”‚
â”‚  8. LLM Provider (Generate response)                                 â”‚
â”‚       â””â”€ Auto-fallback if provider fails                             â”‚
â”‚       â†“                                                              â”‚
â”‚  9. Memory Manager (Store turn in history)                           â”‚
â”‚       â†“                                                              â”‚
â”‚  10. Return to User                                                  â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

```
User Query
    â”‚
    â–¼
Meta-Question Detection?
    â”œâ”€ Keywords: "what topics", "what can you", "what do you know"
    â”‚ â”œâ”€ YES: Allow lower similarity matches
    â”‚ â””â”€ NO: Require high similarity (distance <= 0.35, i.e., similarity >= 0.65)
    â”‚
    â–¼
Document Search (VectorDB)
    â”‚
    â”œâ”€â–º Search for similar documents (k results)
    â”œâ”€â–º Return ranked results with distances
    â”‚
    â–¼
Similarity Validation âš¡ (Hallucination Prevention)
    â”‚
    â”œâ”€ Check: distance <= threshold?
    â”‚ â”œâ”€ META-QUESTION: Allow any distance
    â”‚ â”œâ”€ REGULAR QUESTION: Must pass threshold
    â”‚ â””â”€ NO MATCH: Return "couldn't find information" â†’ END
    â”‚
    â–¼
Context Building
    â”‚
    â”œâ”€â–º Extract and flatten documents
    â”œâ”€â–º Combine with conversation history (from Memory)
    â”œâ”€â–º Add system prompts & constraints
    â”œâ”€â–º Apply reasoning strategy
    â”‚
    â–¼
LLM Processing
    â”‚
    â”œâ”€â–º Chain: [Prompt Template â†’ LLM â†’ Output Parser]
    â”œâ”€â–º Generate response grounded in context
    â”‚
    â–¼
Memory Update
    â”‚
    â”œâ”€â–º Save Q&A pair to conversation history
    â”œâ”€â–º Apply memory strategy:
    â”‚   â”œâ”€ SlidingWindow: Summarize when window full
    â”‚   â”œâ”€ SimpleBuffer: Keep recent messages
    â”‚   â””â”€ Summary: Maintain running summary
    â”‚
    â–¼
Response to User âœ…
    â”‚
    â””â”€â–º Return context-grounded answer
```

**Data Flow Overview:**

The question-to-answer flow follows a 10-step process:

1. **User Query**: The user asks a question through CLI or Streamlit interface.

2. **Meta-Question Detection**: The Persona Handler checks if the question is about the system itself (like "What features do you have?"). If yes, it extracts the answer from the README and returns it immediately.

3. **Query Augmentation**: For regular questions, the Query Processor augments the query with relevant conversation history from the Memory Manager to maintain context for follow-up questions.

4. **Document Search**: The Search Manager converts the query to an embedding and searches the ChromaDB vector database for semantically similar document chunks, returning ranked results.

5. **Similarity Validation**: The Hallucination Prevention module validates that the retrieved documents meet the similarity threshold. Meta-questions allow lower thresholds, but regular questions require high similarity. If no relevant documents are found, the system returns "I'm sorry, that information is not known to me."

6. **Reasoning Strategy Selection**: Based on configuration, a reasoning strategy is selected (Chain-of-Thought, ReAct, Few-Shot Prompting, etc.).

7. **Prompt Construction**: The Prompt Builder combines system prompts, constraints, reasoning instructions, context from documents, and the user question into a complete prompt.

8. **LLM Processing**: The prompt is sent to the selected LLM provider (OpenAI, Groq, or Google Gemini). If the provider fails, the system automatically falls back to the next available provider.

9. **Memory Update**: The question-answer pair is stored in the conversation history using the configured memory strategy (Sliding Window summarization, simple buffer, or running summary).

10. **Response Delivery**: The generated answer is returned to the user, maintaining context for potential follow-up questions.

---

## ğŸ“ Project Structure

```
rag-based-assistant/
â”‚
â”œâ”€â”€ src/                          # Source code modules
â”œâ”€â”€ config/                       # Configuration YAML files
â”œâ”€â”€ data/                         # Document storage
â”œâ”€â”€ tests/                        # Test suite
â”œâ”€â”€ logs/                         # Application logs
â”œâ”€â”€ static/                       # CSS and styling
â”‚
â”œâ”€â”€ requirements.txt              # Production dependencies
â”œâ”€â”€ requirements-test.txt         # Testing dependencies
â”œâ”€â”€ requirements-dev.txt          # Development tools
â”œâ”€â”€ pytest.ini                    # Pytest configuration
â”œâ”€â”€ .pylintrc                     # Pylint configuration
â”œâ”€â”€ .pre-commit-config.yaml       # Pre-commit hooks
â”œâ”€â”€ .env_example                  # Example environment variables
â”‚
â”œâ”€â”€ update_coverage.py            # Coverage badge script
â”œâ”€â”€ UI_GUIDE.md                   # Streamlit UI guide
â”œâ”€â”€ README.md                     # This file
â””â”€â”€ LICENSE                       # License
```

---

## ğŸ§ª Testing

### Run Full Test Suite

```bash
pytest -v

# Run with coverage report
pytest --cov=src --cov-report=html

# View coverage report
open htmlcov/index.html
```

### Pre-Commit Testing

Before you commit, the following checks run automatically:

```bash
# Install pre-commit hooks (one-time setup)
pre-commit install

# Manual run of all checks
pre-commit run --all-files

# Pre-commit checks include:
# âœ… Standard checks (trailing whitespace, file endings, YAML, merge conflicts)
# âœ… Code formatting (Black, isort)
# âœ… Code linting (Flake8, Pylint â‰¥9.5 score)
# âœ… Tests (pytest - all tests must pass)
# âœ… Coverage (minimum 90% required)
```

**If a check fails**, fix the issues and commit again. Most checks (Black, isort, end-of-file-fixer) auto-fix issues, so you may need to stage the changes and retry.

**Note**: Commits will be rejected if test coverage drops below 90%. To bypass (not recommended):
```bash
git commit --no-verify  # Skip pre-commit hooks
```

### Coverage Requirements

- **Minimum Coverage**: 90% (enforced by pre-commit hooks)

### Run Specific Tests

```bash
# Test RAG assistant
pytest tests/test_rag_assistant.py -v

# Test prompt building
pytest tests/test_prompt_builder.py -v

# Test hallucination prevention
pytest tests/test_hallucination_prevention.py -v

# Test memory management
pytest tests/test_memory_manager.py -v
```

### Coverage Badge Updates

The coverage badge in the README is automatically updated in CI/CD:

```bash
# Manual update (for local development)
python update_coverage.py

# This script:
# 1. Reads coverage.xml (generated by pytest)
# 2. Extracts coverage percentage
# 3. Updates README badge with current coverage
# 4. Colors badge based on coverage level (green/yellow/red)
```

The badge is updated:
- âœ… On every push to main (via GitHub Actions)
- âœ… Before pull requests (verify coverage meets threshold)
- âœ… Manually via `python update_coverage.py`


## ğŸ›ï¸ Customization Guide

### Change Memory Strategy

Edit `config.py` to change the memory strategy:

```python
# In src/config.py
MEMORY_STRATEGY = "summarization_sliding_window"  # Options: summarization_sliding_window, simple_buffer, summary, none
```

See [Features](#-features) section for memory strategy details.

### Switch LLM Provider

```bash
# In .env - set which API key to use
OPENAI_API_KEY=...    # Uses OpenAI
```

See [Features](#-features) section for LLM provider details.

### Adjust Document Chunking

```python
# In src/config.py
CHUNK_SIZE_DEFAULT = 2000          # Larger chunks
CHUNK_OVERLAP_DEFAULT = 400        # More overlap for context
RETRIEVAL_K_DEFAULT = 10           # Retrieve more documents
```

### Configure Reasoning Strategy

See [Customization Guide](#-customization-guide) section for detailed reasoning strategy configuration.

### Add Custom Prompts

```python
# In src/prompt_builder.py
def build_system_prompts():
    return [
        "Your custom instruction 1",
        "Your custom instruction 2",
        # ... existing prompts
    ]
```

---


## â“ Troubleshooting

| Issue                | Solution                                                                 |
|----------------------|--------------------------------------------------------------------------|
| API Key not found    | Set `OPENAI_API_KEY`, `GROQ_API_KEY`, or `GOOGLE_API_KEY` in `.env`      |
| No documents found   | Add `.txt` files to `data/` directory or use `assistant.add_documents()` |
| Token limit exceeded | Reduce `CHUNK_SIZE` or enable memory summarization in config             |
| Low answer quality   | Increase `RETRIEVAL_K_DEFAULT` to retrieve more documents                |
| Hallucination issues | Ensure documents are loaded and similarity threshold is set correctly    |

---

### Debug Mode

```bash
# Enable detailed logging
# In log_manager.py, set logging level
logging.basicConfig(level=logging.DEBUG)

# Run with verbose output
pytest -v --log-cli-level=DEBUG
```

---



### Development Setup

```bash
# Fork and clone
git clone https://github.com/sonyjtp/rag-based-assistant.git
cd rag-based-assistant

# Create feature branch
git checkout -b feature/amazing-feature

# Install dev dependencies
pip install -r requirements-test.txt

# Make changes and run tests
pytest tests/ -v

# Commit and push
git add .
git commit -m "feat: add amazing feature"
git push origin feature/amazing-feature

# Create pull request on GitHub
```

### Testing Requirements

All contributions must include:
- âœ… Unit tests for new functionality
- âœ… Integration tests if applicable
- âœ… Documentation updates
- âœ… All tests must pass: `pytest -v`

### Code Style

- Follow PEP 8
- Use type hints
- Write docstrings
- Comment complex logic

---

## ğŸ“š Documentation

This project includes comprehensive documentation for different aspects:

### User Documentation
- **[UI_GUIDE.md](UI_GUIDE.md)** â€” Complete guide to the web interface (Streamlit)
  - Features, components, and user workflows
  - Styling and customization
  - Troubleshooting and performance tips

### Configuration Documentation
- See [Configuration](#-configuration) section for details on:
  - `config/reasoning_strategies.yaml` â€” Reasoning approach configurations
  - `config/memory_strategies.yaml` â€” Memory strategy definitions
  - `config/prompt-config.yaml` â€” System prompts and safety constraints

---

## ğŸ“„ License

This project is licensed under **CC BY-NC-SA 4.0** (Creative Commons Attribution-NonCommercial-ShareAlike 4.0).

**Summary**: Attribution required â€¢ Non-commercial only â€¢ Modifications must use same license

See [LICENSE](LICENSE) file for full details.

---

## ğŸ“ Author

**Sony Jacob Thomas**

---

**Last Updated**: January 2026
**Status**: ğŸ› ï¸ Under Active Development
